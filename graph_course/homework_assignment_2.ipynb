{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d108e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl.nn import SAGEConv, GraphConv, EGATConv\n",
    "from torch.nn import Linear\n",
    "import dgl.function as fn\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk_m\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "from ogb.graphproppred import DglGraphPropPredDataset\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import os\n",
    "from ogb.graphproppred import Evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "750c46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825c0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name = 'ogbg-molhiv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1aeca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffa116",
   "metadata": {},
   "source": [
    "# Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b003aab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGraphDataGenerator(Dataset):\n",
    "    def __init__(self, graphs, labels, device, balanced_sampling=False, batch_size=32):\n",
    "        self.device = device\n",
    "        self.balanced_sampling = balanced_sampling\n",
    "        self.batch_size= batch_size\n",
    "        self.y = labels\n",
    "        self.X = graphs\n",
    "        self.__prepare_samples()\n",
    "        self.__define_batch_size()\n",
    "        self.neg_indices = np.array(list(range(len(self.X_neg))))\n",
    "        self.pos_indices = np.array(list(range(len(self.X_pos))))\n",
    "        self.overall_indices = np.array(list(range(len(self.X))))\n",
    "        \n",
    "    @staticmethod\n",
    "    def floor(x):\n",
    "        if x<1:\n",
    "            tmp = 1\n",
    "        else:\n",
    "            tmp = int(x)\n",
    "        return int(np.ceil(x)) if x % tmp >= 0.5 else int(np.floor(x))\n",
    "       \n",
    "    \n",
    "    def __define_batch_size(self):\n",
    "        counts = Counter(self.y.reshape(-1))\n",
    "        \n",
    "        batch_size_neg = (counts[0]/len(self.X))*self.batch_size\n",
    "        batch_size_neg = self.floor(batch_size_neg)\n",
    "        \n",
    "        batch_size_pos = (counts[1]/len(self.X))*self.batch_size\n",
    "        batch_size_pos = self.floor(batch_size_pos)\n",
    "        \n",
    "        self.batch_size_pos = batch_size_pos\n",
    "        self.batch_size_neg = batch_size_neg\n",
    "    \n",
    "    def __prepare_samples(self):\n",
    "        self.X_neg = self.X[self.y.reshape(-1)==0]\n",
    "        self.X_pos = self.X[self.y.reshape(-1)==1]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index+1>self.__len__()-1:\n",
    "            raise StopIteration\n",
    "        \n",
    "        if self.balanced_sampling:\n",
    "            \n",
    "            indices_neg = self.neg_indices[index*self.batch_size_neg:(index+1)*self.batch_size_neg]\n",
    "            indices_pos = self.pos_indices[index*self.batch_size_pos:(index+1)*self.batch_size_pos]\n",
    "\n",
    "            X = np.concatenate((self.X_pos[indices_pos], self.X_neg[indices_neg]))\n",
    "            y = np.concatenate((self.y[indices_pos], self.y[indices_neg]))\n",
    "        \n",
    "            return dgl.batch(X).to(self.device), torch.Tensor(y).to(self.device)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            indices = self.overall_indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            \n",
    "            return dgl.batch(self.X[indices]).to(self.device), torch.Tensor(self.y[indices]).to(self.device)\n",
    "        \n",
    "    \n",
    "    def shuffle_indices(self):\n",
    "        np.random.shuffle(self.neg_indices)\n",
    "        np.random.shuffle(self.pos_indices)\n",
    "        np.random.shuffle(self.overall_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11d8214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DglGraphPropPredDataset(name = 'ogbg-molhiv') \n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "labels = np.array(dataset.labels)\n",
    "graphs = np.array(dataset.graphs)\n",
    "train_graphs, val_graphs, test_graphs  = graphs[train_idx], graphs[valid_idx],  graphs[test_idx]\n",
    "train_labels, valid_labels, test_labels = labels[train_idx], labels[valid_idx], labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11fdf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graphs_batched = dgl.batch(test_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56b998ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 31669, 1: 1232})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_labels.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b65dc1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41127, 32901, 4113, 4113)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(train_graphs), len(val_graphs), len(test_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee9b0b",
   "metadata": {},
   "source": [
    "## class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99e550d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50343e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', y=train_labels.reshape(-1),\n",
    "                                     classes=np.unique(train_labels.reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868259ff",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cd37571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(labels, scores, threshold=0.5):\n",
    "    labels = np.hstack([i.reshape(-1) for i in labels])\n",
    "    scores = np.hstack([i.reshape(-1) for i in scores])\n",
    "    pred = (np.array(scores)>threshold).astype(int)\n",
    "    f1 = sk_m.f1_score(y_pred=pred, y_true=labels, average='binary')\n",
    "    roc = sk_m.roc_auc_score(y_score=scores, y_true=labels)\n",
    "    return f1, roc\n",
    "\n",
    "def BCELoss_class_weighted(weights):\n",
    "\n",
    "    def loss(input, target):\n",
    "        input = torch.clamp(input,min=1e-7,max=1-1e-7)\n",
    "        bce = - weights[1] * target * torch.log(input) - (1 - target) * weights[0] * torch.log(1 - input)\n",
    "        return torch.mean(bce)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train(train_generator, val_generator, model, \n",
    "          epochs=10, lr=1e-3, weight_decay=1e-5,\n",
    "          class_weights=None,\n",
    "          use_edge_feature=False, shuffle=False, early_stopping=None):\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    loss_func = BCELoss_class_weighted(class_weights)\n",
    "    \n",
    "    if not (class_weights is None):\n",
    "        class_weights = torch.FloatTensor(class_weights)\n",
    "        loss_func = BCELoss_class_weighted(class_weights)\n",
    "    else:\n",
    "        loss_func = F.binary_cross_entropy\n",
    "\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_scores = []\n",
    "        train_labels = []\n",
    "        loss_train_holder = []\n",
    "        \n",
    "        val_scores = []\n",
    "        val_loss_holder = []\n",
    "        val_labels = []\n",
    "        \n",
    "        for train_graph, label in tqdm(train_generator):\n",
    "            if use_edge_feature:\n",
    "                logits_train = model(train_graph, train_graph.ndata['feat'].to(torch.float32),\\\n",
    "                                     train_graph.edata['feat'].to(torch.float32))\n",
    "            else:\n",
    "                logits_train = model(train_graph, train_graph.ndata['feat'])\n",
    "            sigmoided_train = F.sigmoid(logits_train)\n",
    "            loss_train = loss_func(sigmoided_train, label)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_labels.append(label.numpy())\n",
    "            train_scores.append(sigmoided_train.detach().numpy())\n",
    "            loss_train_holder.append(loss_train.detach().numpy())\n",
    "            \n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            for val_graph, val_label in val_generator:\n",
    "                \n",
    "                if use_edge_feature:\n",
    "                    logits_val = model(val_graph, val_graph.ndata['feat'].to(torch.float32), \\\n",
    "                                   val_graph.edata['feat'].to(torch.float32))\n",
    "                else:\n",
    "                    logits_val = model(val_graph, val_graph.ndata['feat'])\n",
    "                    \n",
    "                sigmoided_val = F.sigmoid(logits_val)\n",
    "                \n",
    "                loss_val = loss_func(sigmoided_val, val_label)\n",
    "                \n",
    "                \n",
    "                val_labels.append(val_label.numpy())\n",
    "                val_scores.append(sigmoided_val.detach().numpy())\n",
    "                val_loss_holder.append(loss_val)\n",
    "            \n",
    "        train_f1, train_roc = metrics(train_labels, train_scores)\n",
    "        val_f1, val_roc = metrics(val_labels, val_scores)\n",
    "        \n",
    "\n",
    "        print('In epoch {}, Train loss: {:.3f}, train roc: {:.3f}, train f1: {:.3f},'\n",
    "              ' val loss: {:.3f}, val roc: {:.3f}, val f1 : {:.3f}'.format(\n",
    "            e, np.mean(loss_train_holder), train_roc, train_f1, np.mean(val_loss_holder), \\\n",
    "        val_roc, val_f1))\n",
    "        \n",
    "        if early_stopping:\n",
    "            early_stopping(val_roc, model)\n",
    "            print('Early stopping extemum : {}'.format(early_stopping.extemum_value))\n",
    "            if early_stopping.early_stop:\n",
    "                print('Stopping early')\n",
    "                model = early_stopping.best_model\n",
    "                break\n",
    "        \n",
    "        if shuffle:\n",
    "            train_generator.shuffle_indices()\n",
    "            \n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6af20d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2032fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, mode='min'):\n",
    "        assert mode in ['min','max'], 'Mode should be min or max'\n",
    "        self.mode = operator.lt if mode=='min' else operator.gt \n",
    "        self.tolerance = tolerance\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.extemum_value = None\n",
    "        self.best_model = None\n",
    "        \n",
    "        \n",
    "    def __call__(self, val, model):\n",
    "        if self.extemum_value is None:\n",
    "            self.extemum_value = val\n",
    "            self.best_model = model\n",
    "        else:\n",
    "            if not self.mode(val, self.extemum_value):\n",
    "                self.counter+=1\n",
    "            else:\n",
    "                self.extemum_value = val\n",
    "                self.best_model = model\n",
    "        \n",
    "        if self.counter==self.tolerance:\n",
    "            self.early_stop=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "64097f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "class GraphModelNoEdge(nn.Module):\n",
    "    def __init__(self, emb_shape=100):\n",
    "        set_seed(0)\n",
    "        super(GraphModelNoEdge, self).__init__()\n",
    "        self.emb = AtomEncoder(emb_shape)\n",
    "        self.node_conv1 = GraphConv(emb_shape, 256, allow_zero_in_degree=True)\n",
    "        self.node_conv2 = SAGEConv(256, 128, 'lstm')\n",
    "        self.node_conv3 = SAGEConv(128, 64, 'mean')\n",
    "        self.node_conv4 = SAGEConv(64, 1, 'mean')\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "\n",
    "        \n",
    "    def forward(self, g, n_data):\n",
    "        h_nodes = self.emb(n_data)\n",
    "        h_nodes = self.node_conv1(g, h_nodes)\n",
    "        h_nodes = F.relu(h_nodes)\n",
    "        h_nodes = self.dropout1(self.node_conv2(g, h_nodes))\n",
    "        h_nodes = F.relu(h_nodes)\n",
    "        h_nodes = self.node_conv3(g, h_nodes)\n",
    "        h_nodes = F.relu(h_nodes)\n",
    "        h_nodes = self.node_conv4(g, h_nodes)\n",
    "        g.ndata['h'] = h_nodes\n",
    "        h_nodes = dgl.mean_nodes(g, 'h')\n",
    "        return h_nodes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ca06307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    }
   ],
   "source": [
    "model = GraphModelNoEdge(100)\n",
    "model.to(device)\n",
    "batch_size = 64\n",
    "balanced_sampling = False\n",
    "use_edge_feature = False\n",
    "early_stopping = EarlyStopping(tolerance=3, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "948a53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CustomGraphDataGenerator(train_graphs, train_labels,device=device, batch_size=batch_size,\n",
    "                                          balanced_sampling=balanced_sampling)\n",
    "valid_generator = CustomGraphDataGenerator(val_graphs, valid_labels, device=device, batch_size=batch_size,\n",
    "                                          balanced_sampling=balanced_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8972aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/515 [00:00<?, ?it/s]/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|████████████████████████████████████████▉| 514/515 [02:43<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, Train loss: 0.677, train roc: 0.618, train f1: 0.096, val loss: 0.958, val roc: 0.675, val f1 : 0.039\n",
      "Early stopping extemum : 0.6752702058638131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/515 [00:00<?, ?it/s]/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|████████████████████████████████████████▉| 514/515 [02:42<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 1, Train loss: 0.656, train roc: 0.656, train f1: 0.115, val loss: 0.943, val roc: 0.693, val f1 : 0.039\n",
      "Early stopping extemum : 0.6929754162630875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/515 [00:00<?, ?it/s]/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/volodymyrkovenko/envs/env_lviv_ds/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      " 23%|█████████▋                               | 121/515 [00:33<01:59,  3.29it/s]"
     ]
    }
   ],
   "source": [
    "model = train(train_generator, valid_generator, model, class_weights=class_weights, weight_decay=1e-5,\n",
    "             epochs=25, use_edge_feature=use_edge_feature, \n",
    "             early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321890f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5324a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model(test_graphs_batched, test_graphs_batched.ndata['feat'])\n",
    "predicted = F.sigmoid(predicted).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb76976",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.eval({\"y_true\": test_labels, \"y_pred\": predicted})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c728a9",
   "metadata": {},
   "source": [
    "# Table with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32e775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cda8584",
   "metadata": {},
   "source": [
    "# Conclusions:\n",
    "### 1) Using sampling w.r.t distribution in the dataset (balanced_sampling) on average gives worser results; \n",
    "### 2) Using weighted loss improves rocauc score (basically because of the highly imbalanced weights)\n",
    "### 3) Adding l2 regularization helps \n",
    "### 4) Using embeddings for node features hepls a lot, no overfitting detected (basically because of the better representation of categorical features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce9e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
